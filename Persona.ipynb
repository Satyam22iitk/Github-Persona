{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name - Satyam Srivastava  \n",
        "College IIT Kanpur  \n",
        "Final Year Undergraduate  \n",
        "satyamsriv22@iitk.ac.in  \n",
        "+91 6388443533"
      ],
      "metadata": {
        "id": "w4mvlllxdKY9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fOnwMpgETo3L"
      },
      "outputs": [],
      "source": [
        "!pip install praw --quiet\n",
        "import logging\n",
        "logging.getLogger(\"praw\").setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"8RNsm7uy-KzMuZtfwtwtMg\",\n",
        "    client_secret=\"w4nW6HYfrc3YsZQ0JXZr9WrSEE4wLA\",\n",
        "    user_agent=\"script:reddit.persona:v1.0 (by u/Satyam)\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Reddit Login Successful:\", reddit.read_only)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DK_vjdUTs4w",
        "outputId": "3a38a0ad-a789-4eab-9bf3-2a4e4835a6f7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Reddit Login Successful: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_user_data(username):\n",
        "    user = reddit.redditor(username)\n",
        "    comments, posts = [], []\n",
        "\n",
        "    try:\n",
        "        for c in user.comments.new(limit=100):\n",
        "            comments.append((c.body, f\"https://reddit.com{c.permalink}\"))\n",
        "        for p in user.submissions.new(limit=50):\n",
        "            content = p.title + \"\\n\" + p.selftext\n",
        "            posts.append((content, f\"https://reddit.com{p.permalink}\"))\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching user data:\", e)\n",
        "\n",
        "    return comments, posts\n"
      ],
      "metadata": {
        "id": "TvNWSiM-TvSO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def analyze_persona(comments, posts):\n",
        "    persona = {\n",
        "        \"traits\": [],\n",
        "        \"interests\": [],\n",
        "        \"opinions\": [],\n",
        "        \"citations\": []\n",
        "    }\n",
        "\n",
        "    keywords = [\"I believe\", \"I think\", \"In my opinion\", \"I feel\", \"I love\", \"My favorite\"]\n",
        "\n",
        "    for text, link in comments + posts:\n",
        "        lower = text.lower()\n",
        "\n",
        "        if any(k.lower() in lower for k in keywords):\n",
        "            if \"believe\" in lower or \"think\" in lower:\n",
        "                persona[\"opinions\"].append((text, link))\n",
        "            elif \"love\" in lower or \"favorite\" in lower:\n",
        "                persona[\"interests\"].append((text, link))\n",
        "\n",
        "        if re.search(r\"\\b(curious|friendly|sarcastic|kind|thoughtful)\\b\", lower):\n",
        "            persona[\"traits\"].append((text, link))\n",
        "\n",
        "    persona[\"citations\"] = list(set([link for _, link in comments + posts][:10]))\n",
        "\n",
        "    return persona\n"
      ],
      "metadata": {
        "id": "-7nNQtimTx1H"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_persona(username, persona):\n",
        "    filename = f\"{username}.txt\"\n",
        "\n",
        "    output = f\"USER: {username}\\n\\n--- PERSONA ---\\n\\n\"\n",
        "\n",
        "    output += \"üë§ Personality Traits:\\n\"\n",
        "    for t in persona[\"traits\"]:\n",
        "        output += f\"- {t[0]} [Source: {t[1]}]\\n\"\n",
        "\n",
        "    output += \"\\nüìö Interests:\\n\"\n",
        "    for i in persona[\"interests\"]:\n",
        "        output += f\"- {i[0]} [Source: {i[1]}]\\n\"\n",
        "\n",
        "    output += \"\\nüéØ Opinions:\\n\"\n",
        "    for o in persona[\"opinions\"]:\n",
        "        output += f\"- {o[0]} [Source: {o[1]}]\\n\"\n",
        "\n",
        "    output += \"\\nüîó Source References:\\n\"\n",
        "    for c in persona[\"citations\"]:\n",
        "        output += f\"- {c}\\n\"\n",
        "\n",
        "    # ‚úÖ Print it in notebook\n",
        "    print(output)\n",
        "\n",
        "    # üíæ Save to file\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(output)\n",
        "\n",
        "    print(f\"\\n‚úÖ Persona saved to: {filename}\")\n",
        "    return filename\n"
      ],
      "metadata": {
        "id": "3vy3yG_cT4Ld"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_persona_generator():\n",
        "    url = input(\"üîó Enter Reddit profile URL: \").strip()\n",
        "    username = url.rstrip('/').split('/')[-1]\n",
        "\n",
        "    print(f\"\\n‚è≥ Fetching data for: {username}...\\n\")\n",
        "    comments, posts = fetch_user_data(username)\n",
        "\n",
        "    if not comments and not posts:\n",
        "        print(\"‚ö†Ô∏è No data found.\")\n",
        "        return\n",
        "\n",
        "    persona = analyze_persona(comments, posts)\n",
        "    filename = save_persona(username, persona)\n",
        "\n",
        "    return filename\n",
        "\n",
        "filename = run_persona_generator()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK0dN5eVT7pM",
        "outputId": "294361c4-fe05-477e-a3a0-13e161999f5b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó Enter Reddit profile URL: https://www.reddit.com/user/kojied/\n",
            "\n",
            "‚è≥ Fetching data for: kojied...\n",
            "\n",
            "USER: kojied\n",
            "\n",
            "--- PERSONA ---\n",
            "\n",
            "üë§ Personality Traits:\n",
            "- Not in Chelsea but Washington square park has the pigeon whisperer. Bear in mind he‚Äôs definitely eccentric and curses a lot so might not be a family friendly guy to talk to.\n",
            "Also the corner of 46th and 6Av always has insane number of pigeons. Like a lot. [Source: https://reddit.com/r/AskNYC/comments/1hpnjqr/ridiculous_question_anybody_know_where_in_chelsea/m4j0ese/]\n",
            "- Can you actually ‚Äúwork‚Äù in AVP?\n",
            "I‚Äôm curious if people have been able to fully port their workflow into AVP.\n",
            "\n",
            "I‚Äôve been trying to actually use the Vision Pro to get some work done, but without github and visual studio code, it‚Äôs not been the easiest (also obviously no terminal). I could use Mac virtual display, but since I have a M1 MBP the latency is noticeable to the point it‚Äôs an adverse experience. I already dropped $4k on this device, renewing my MBP just so I can use it with my AVP is asking a bit too much‚Ä¶\n",
            "\n",
            "Also where‚Äôs Xcode? If Apple wants AVP to be a ‚Äúwork device‚Äù, they gotta have at least Xcode right?\n",
            "\n",
            "I can get the simple stuff like emails done through AVP, but if this device can‚Äôt replace my entire workflow, I don‚Äôt know if I can justify the price. I‚Äôm sure it‚Äôll get resolved down the line (more of a software issue than hardware constraints), but curious to hear how realistic it is for people to port over their workflow to AVP, and what apps you‚Äôd like to see ASAP. [Source: https://reddit.com/r/VisionPro/comments/1aiwqa2/can_you_actually_work_in_avp/]\n",
            "\n",
            "üìö Interests:\n",
            "- I‚Äôm not using it as frequently as I had wished. The battery life is too low to use while flying (even with the extra battery bank it won‚Äôt last a full cross country flight)\n",
            "\n",
            "I‚Äôve not used it at work yet since it‚Äôs socially awkward, and people see it weird.¬†\n",
            "I‚Äôll use it at wfh now that they have widescreen but 1-2hrs is the max I can do before I need a break\n",
            "\n",
            "But holy shit. When I enter immersive videos on appleTV I love it. It‚Äôs the coolest thing in the world. [Source: https://reddit.com/r/VisionPro/comments/1gw2bof/should_i_get_one/ly658s7/]\n",
            "- At that height you should check out 260 sample sale for your favorite brands. They have good brands that do sales on samples throughout the year. A lot of the sizes left over are XS or XL, so it‚Äôd fit you well.\n",
            "\n",
            "In terms of brands, here‚Äôs some of my favorites\n",
            "- APC\n",
            "- Acne studios\n",
            "- Rag&Bone\n",
            "- Maison kitsune\n",
            "\n",
            "You should also check out second street for second hand clothing. They‚Äôve got some good hauls there [Source: https://reddit.com/r/AskNYC/comments/1gshr7i/fashionable_ppl_of_nyc_where_do_you_shop_for_mens/lxfmito/]\n",
            "- I love that considering this was at BM she could've been entirely trolling and you would never know [Source: https://reddit.com/r/BurningMan/comments/1eto5ep/in_order_to_be_more_transparent_we_have_decided/lifmwrz/]\n",
            "\n",
            "üéØ Opinions:\n",
            "- So in general each family will eat each type of food equally. Which means those with low supply are more likely to be consumed first.\n",
            "\n",
            "Eggs I believe each plot only produces one per month, so it's helpful, but won't be sufficient to maintain food diversity [Source: https://reddit.com/r/ManorLords/comments/1lihry5/am_i_doing_something_wrong_with_food_management_i/mzc2uit/]\n",
            "- \\- the hype has definitely faded, you can see that with the price as well as the number of people discussing it on X, or even here  \n",
            "\\- haven't seen much innovation in the space at all, the momentum seems to have shifted to solana memecoins, and dissipated after that  \n",
            "\\- again, people no longer seem interested. I found linksDAO to be an interesting concept of fractionally owning a golf course, and they're still active but not much hype around them anymore either. Most major brand NFT collaborations have died down as well  \n",
            "\\- the NFT craze has not settled into something sustainable, it's dead. Can it come back? Possibly, it has happened before, when cryptopunks and cryptokitties were first hot in 2017-ish, then died, then came back during 2020-2022.  \n",
            "\\- will there be a big boom? I personally don't think it would in the way we think of NFTs as collectables. A major thesis was around digital scarcity, and that seemed possible during covid, but post covid people went back to f2f interactions. Digital scarcity could become a hot topic again if we see a broader adoption of VR or even XR, but that seems a bit down the line. I think fractional ownership of assets could be interesting, but they'd just be fungible tokens, not NFT\n",
            "\n",
            "I see so many one-off posts on this community with only a couple responses. Can't believe there's 2.7M members here. That alone should tell you that NFTs are no longer something people are interested in. I'd love to be proven wrong, since I feel that there was alot of potential, but so far it seems like the community is dead [Source: https://reddit.com/r/NFT/comments/1l2gcmt/nfts_in_2025_where_are_we_headed/mvt4t5c/]\n",
            "- Oh interesting, I've been going about once a month recently but haven't noticed. I'm going on Sunday again so will let you know what I think [Source: https://reddit.com/r/FoodNYC/comments/1h87emd/did_rakus_noodle_recipe_change/m0rzprt/]\n",
            "- I think you should just shave it off entirely. Get this shaver, it's a bit pricy but you'll never have to worry about shaving again (until you get a blade replacement in a few years)  \n",
            "[https://www.amazon.com/dp/B07W5SV5P8?psc=1&ref=ppx\\_yo2ov\\_dt\\_b\\_product\\_details](https://www.amazon.com/dp/B07W5SV5P8?psc=1&ref=ppx_yo2ov_dt_b_product_details) [Source: https://reddit.com/r/GenZ/comments/1gc4gbc/i_want_to_be_more_conventionally_attractive_you/ltqzj9f/]\n",
            "- There are some key technologies which can give you significant advantage in the early game, either in military or in science. The ones for military are composite Bowmans, chariots, crossbow etc, but the great library doesn‚Äôt really help you obtain these since they‚Äôre on the opposite side of the tech tree. As in, if you want to beeline for those it‚Äôs faster to research those tech instead of researching and beelining for great library.\n",
            "\n",
            "I think the great library can be beneficial in getting to theology faster, which will get you to¬†borobudur. That‚Äôs game changing if you are pushing for religion (which honestly you should unless there are reasons not to).¬†\n",
            "\n",
            "The great scientist points are great to have early on, although you often use them for bulk popping once you have research labs up and running.\n",
            "\n",
            "I usually play at deity where the AI starts miles ahead in technology so don‚Äôt even bother, but if you‚Äôre playing king or emperor it should be a decent strat. [Source: https://reddit.com/r/civ5/comments/1fw0b0w/is_the_great_library_really_not_worth_it_has_my/lqb18ti/]\n",
            "- At this point I've written off all my purchases as a loss. I think I had like 5k in it at some point, but I'm not even sure if I was able to take it out via ECOMI either :/\n",
            "\n",
            "It's not just an veve issue, from BitClout to friendtech to Rally to NFTs in general, it's basically gone.\n",
            "\n",
            "I'm treating it as a every expensive life lesson and will be much more cautious when a new hype begins [Source: https://reddit.com/r/NFT/comments/1fg5e27/marvel_and_disney_nfts_promising_true_ownership/ln001f2/]\n",
            "- Would you guys like to see Pokemon Go in AVP?\n",
            "Hi guys,\n",
            "\n",
            "I think Pokemon could be one of the killer use case for the vision pro. Imagine, you could fight players from around the world from the comfort of your couch. With the recent controversy around Palworld, they're looking for the next \"Pokemon Go\" that would propel their franchise to the next level.\n",
            "\n",
            "Being Japanese, I happen to know a few key decision makers both in the Pokemon Company as well as Niantic. Alot of the in-game designs are transferrable, and I believe it's a matter of time until Niantic's Lightship ARDK will work on AVP.\n",
            "\n",
            "*What should I tell them? Lmk if you have thoughts or useful links/videos I should forward to them.*\n",
            "\n",
            "I'm confident that this will eventually become a thing, but the faster they ship the more AVP adoption we'll see.\n",
            "\n",
            "[personal info redacted for obvious reasons](https://preview.redd.it/be7qbqfg5qgc1.png?width=800&format=png&auto=webp&s=21fec81575a29fa53fc01639e368980dc4c5ac6f) [Source: https://reddit.com/r/VisionPro/comments/1ajbkqm/would_you_guys_like_to_see_pokemon_go_in_avp/]\n",
            "- Tracking our individual impacts on the world through ESG ratings\n",
            "&#x200B;\n",
            "\n",
            "[Mock-up of ESG scores ](https://preview.redd.it/btc0a5nqmhjb1.png?width=632&format=png&auto=webp&s=13920d7c88791b2579b6167e5fe135a136731ef7)\n",
            "\n",
            "&#x200B;\n",
            "\n",
            "We've had ESG ratings for decades now, but it hasn't  played a significant role in the eyes of the consumer. Sure it has developed new investing policies and has made some impact from the shareholder side, but as someone who's worked in environmental consulting, I felt that we needed a more direct way of getting ESG ratings into the mass conscience.\n",
            "\n",
            "**Do you think individuals should be aware of our own ESG rating?**\n",
            "\n",
            "I feel that companies would take ESG ratings  seriously if consumers changed their purchase behaviors based on the score.\n",
            "\n",
            "The current method of consumer activism has yielded lackluster results. This is because once the news dies down, consumers forget about the scandal and go back to normal purchasing behavior. In addition, companies aren't really incentivized to make changes, since consumers hear about the scandal, but rarely stay informed about what was done about it.\n",
            "\n",
            "The first step towards voting with our dollars is to be aware of our current ESG impact. This can be approximated through the ESG score of the companies you are purchasing goods/services from, multiplied by the dollar amount of your purchase. [Sustainalytics](https://www.sustainalytics.com/) has a comprehensive ESG rating for most public companies. For purchases from businesses that are private (and doesn't have any ESG rating), we can approximate from comparable public companies, or use other indicators (BCorp, Fair Trade, etc.)\n",
            "\n",
            "Please let me know what you think!\n",
            "\n",
            "Individual ESG scores could elevate sustainable conscience to another level, which would lead to climate activism on a larger scale. [Source: https://reddit.com/r/ClimateOffensive/comments/15xgmea/tracking_our_individual_impacts_on_the_world/]\n",
            "- How do you decide what to buy and not buy?\n",
            "I've been lurking in this channel for a while now, and have been greatly inspired by the ways people have found ways to stretch their money. This got me thinking, is there a way to develop a mental model on what we buy or don't buy?\n",
            "\n",
            "I feel that most people decide what to buy based on past experiences, gut feeling, or the mood of that day. But is there a way to better understand what we get our \"gratification\" from, and track this?\n",
            "\n",
            "My initial idea was an app that would enable users to track the \"gratification\" they receive from their purchases. If you regret what you bought, you can record a decline in the gratification, or if you found the purchase better than you expected, you can record an increase.\n",
            "\n",
            "Of course, this would not necessarily apply to all purchases. Some things (rent, insurance, etc.) do not yield any gratification scores, but many purchases (clothes, going out, etc.) could.\n",
            "\n",
            "&#x200B;\n",
            "\n",
            "Would love to hear how you make your purchase decisions, and if there's a mental model you follow!\n",
            "\n",
            "(photo is a mockup of the idea I'm working on)\n",
            "\n",
            "https://preview.redd.it/w7dzy8gi0jib1.png?width=616&format=png&auto=webp&s=803a36d08e4dce445fef0c9b07bbf9a3a1ab97a4 [Source: https://reddit.com/r/Frugal/comments/15szxcx/how_do_you_decide_what_to_buy_and_not_buy/]\n",
            "\n",
            "üîó Source References:\n",
            "- https://reddit.com/r/ChatGPT/comments/1lvtwj3/i_used_ai_to_create_this_short_film_on_human/n2b07h0/\n",
            "- https://reddit.com/r/ManorLords/comments/1lg0qii/the_ability_to_combine_regions_or_make_aivassal/myulv47/\n",
            "- https://reddit.com/r/ManorLords/comments/1lscpmo/how_does_influence_on_hard_work/n1hhd7z/\n",
            "- https://reddit.com/r/ManorLords/comments/1ly3nuf/my_granary_burned_down/n2r16t2/\n",
            "- https://reddit.com/r/ManorLords/comments/1lse9cn/great_game_i_hope_there_is_something_new_added_in/n1i5k2p/\n",
            "- https://reddit.com/r/ManorLords/comments/1lwfdh8/anyone_else_having_an_issue_where_their_trading/n2dn0vm/\n",
            "- https://reddit.com/r/ManorLords/comments/1lq4lst/this_is_acceptable/n1089i9/\n",
            "- https://reddit.com/r/ManorLords/comments/1ljgy2w/confession/mzopv8i/\n",
            "- https://reddit.com/r/ManorLords/comments/1lihry5/am_i_doing_something_wrong_with_food_management_i/mzc2uit/\n",
            "- https://reddit.com/r/ManorLords/comments/1lse9cn/great_game_i_hope_there_is_something_new_added_in/n1i52vu/\n",
            "\n",
            "\n",
            "‚úÖ Persona saved to: kojied.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "q0uHtyurUHvY",
        "outputId": "5056efe9-07a1-403c-8751-c0fa948c878c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b39fcf7d-f6d9-4e24-a5a9-1a350b4e02d6\", \"kojied.txt\", 12568)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}